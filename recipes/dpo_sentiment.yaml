dataset_name: data/senti_data/tweet_sentiment_preference_long
model_name_or_path: sft-weights/gpt2-long-s480
per_device_train_batch_size: 32
per_device_eval_batch_size: 64
learning_rate: 5.0e-6
gradient_accumulation_steps: 1
num_train_epochs: 1
logging_steps: 10
eval_strategy: steps
eval_steps: 10
save_strategy: steps
save_steps: 40
run_name: g2-sent-long-sigmoid-dpo
output_dir: outputs/g2-sent-long-sigmoid-dpo
warmup_ratio: 0.1
remove_unused_columns: False
report_to: wandb
bf16: True
dataset_num_proc: 32
use_peft: False