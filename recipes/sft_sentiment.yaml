dataset_name: data/senti_data/tweet_sentiment_sft_long
model_name_or_path: gpt2
dataset_text_field: None
per_device_train_batch_size: 16
per_device_eval_batch_size: 32
learning_rate: 1.41e-5
gradient_accumulation_steps: 1
max_steps: 128
logging_steps: 1
eval_strategy: steps
eval_steps: 8
save_strategy: steps
save_steps: 16
run_name: g2-sent-long-sft
output_dir: outputs/g2-sent-long-sft
warmup_ratio: 0.1
remove_unused_columns: False
report_to: wandb
bf16: True
dataset_num_proc: 16
use_peft: False
packing: True